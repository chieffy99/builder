{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô **‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÇ‡∏Ñ‡πâ‡∏î** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏â‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì **Meow!!!** üöÄ  \n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ 1. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**\n",
    "‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏î ‡πÜ ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ExtraTreeRegressor from version 1.1.3 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m iso_forest \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso_forest.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Isolation Forest\u001b[39;00m\n\u001b[0;32m      7\u001b[0m lof \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlof.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Local Outlier Factor\u001b[39;00m\n\u001b[0;32m      8\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbscan.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# DBSCAN Clustering\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\pickle.py:1255\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1255\u001b[0m         dispatch[key[\u001b[38;5;241m0\u001b[39m]](\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:402\u001b[0m, in \u001b[0;36mNumpyUnpickler.load_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_build\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    395\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called to set the state of a newly created object.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    We capture it to replace our place-holder objects, NDArrayWrapper or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    NDArrayWrapper is used for backward compatibility with joblib <= 0.9.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     Unpickler\u001b[38;5;241m.\u001b[39mload_build(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# For backward compatibility, we support NDArrayWrapper objects.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], (NDArrayWrapper, NumpyArrayWrapper)):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\pickle.py:1759\u001b[0m, in \u001b[0;36m_Unpickler.load_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m setstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(inst, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setstate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1759\u001b[0m     setstate(state)\n\u001b[0;32m   1760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1761\u001b[0m slotstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m_tree.pyx:867\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.__setstate__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:1573\u001b[0m, in \u001b[0;36msklearn.tree._tree._check_node_ndarray\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "### **üìå ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ**python\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
    "iso_forest = joblib.load(\"iso_forest.pkl\")  # Isolation Forest\n",
    "lof = joblib.load(\"lof.pkl\")  # Local Outlier Factor\n",
    "dbscan = joblib.load(\"dbscan.pkl\")  # DBSCAN Clustering\n",
    "scaler = joblib.load(\"scaler.pkl\")  # Standard Scaler\n",
    "\n",
    "\n",
    "### **üìå ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á (‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á)**\n",
    "python\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á, 20 features)\n",
    "new_data = np.random.normal(0, 1, (10, 20))\n",
    "\n",
    "# ‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "new_data_scaled = scaler.transform(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## **üîπ 2. ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Anomaly Detection**\n",
    "### **üìå ‡πÉ‡∏ä‡πâ Isolation Forest ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥**\n",
    "```python\n",
    "predictions_if = iso_forest.predict(new_data_scaled)\n",
    "print(\"Isolation Forest Predictions:\", predictions_if)  # -1 = ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥, 1 = ‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "```\n",
    "\n",
    "### **üìå ‡πÉ‡∏ä‡πâ Local Outlier Factor (LOF) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥**\n",
    "```python\n",
    "predictions_lof = lof.fit_predict(new_data_scaled)\n",
    "print(\"Local Outlier Factor Predictions:\", predictions_lof)  # -1 = ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥, 1 = ‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--\n",
    "\n",
    "## **üîπ 3. ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Clustering**\n",
    "### **üìå ‡πÉ‡∏ä‡πâ DBSCAN ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**\n",
    "```python\n",
    "cluster_labels = dbscan.fit_predict(new_data_scaled)\n",
    "print(\"DBSCAN Cluster Labels:\", cluster_labels)  # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏•‡∏±‡∏™‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà (-1 = outlier)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "## **üîπ 4. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á**\n",
    "### **üìå ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Light Curve ‡∏´‡∏£‡∏∑‡∏≠ Signal Processing**\n",
    "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å **Radio Transients** ‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CSV (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå signal_data.csv)\n",
    "df = pd.read_csv(\"signal_data.csv\")\n",
    "\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏ä‡πà‡∏ô 20 features)\n",
    "X_real = df.iloc[:, :20].values\n",
    "\n",
    "# ‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "X_real_scaled = scaler.transform(X_real)\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Isolation Forest ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "predictions_if_real = iso_forest.predict(X_real_scaled)\n",
    "print(\"Real Data Anomaly Predictions:\", predictions_if_real)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "## **üîπ 5. ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• (Train ‡πÄ‡∏û‡∏¥‡πà‡∏°)**\n",
    "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ **‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°** ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢:\n",
    "\n",
    "### **üìå ‡∏ù‡∏∂‡∏Å Isolation Forest ‡πÉ‡∏´‡∏°‡πà**\n",
    "python\n",
    "iso_forest_new = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso_forest_new.fit(X_real_scaled)\n",
    "joblib.dump(iso_forest_new, \"iso_forest_updated.pkl\")  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà\n",
    "\n",
    "\n",
    "### **üìå ‡∏ù‡∏∂‡∏Å DBSCAN ‡πÉ‡∏´‡∏°‡πà**\n",
    "python\n",
    "dbscan_new = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_new.fit(X_real_scaled)\n",
    "joblib.dump(dbscan_new, \"dbscan_updated.pkl\")  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **üéØ ‡∏™‡∏£‡∏∏‡∏õ**\n",
    "‚úÖ **‡πÉ‡∏ä‡πâ Isolation Forest & LOF** ‚Üí ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥  \n",
    "‚úÖ **‡πÉ‡∏ä‡πâ DBSCAN** ‚Üí ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•  \n",
    "‚úÖ **‡πÉ‡∏ä‡πâ Scaler** ‚Üí ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ  \n",
    "‚úÖ **‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ** ‚Üí ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì  \n",
    "\n",
    "üì• **‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Hackathon ‡πÅ‡∏•‡πâ‡∏ß! ‡πÅ‡∏à‡πâ‡∏á‡∏â‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° Meow!!!** üöÄüò∫"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
